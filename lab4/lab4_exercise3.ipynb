{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4, Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data \n",
    "\n",
    "The data is separated into three folders: Attack_Data_Master, Training_Data_Master, and Validation_Data_Master\n",
    "These can be found here:\n",
    "data/exercise3/Training_Data_Master\n",
    "data/exercise3/Validation_Data_Master\n",
    "data/exercise3/Attack_Data_Master\n",
    "\n",
    "All of the data in Training_Data_Master and Validation_Data_Master is normal, \n",
    "and all the data in Attack_Data_Master is malicious\n",
    "\n",
    "For the purpose of this exercise, you will ignore the predefined training/validation splits, and simply use Training_Data_Master\n",
    "and Validation_Data_Master as a single pool of normal data\n",
    "\n",
    "As mentioned, each system call trace is stored as a single file.  Treat each system call trace as a separate datapoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the normal system call traces (i.e., everything in Training_Data_Master and Validation_Data_Master)\n",
    "\n",
    "# CODE HERE\n",
    "normal_data = []\n",
    "path = ['data/exercise3/Training_Data_Master', 'data/exercise3/Validation_Data_Master']\n",
    "for p in path:\n",
    "    files = [os.path.join(p, f) for f in os.listdir(p)]\n",
    "    for f in files:\n",
    "        if '.txt' not in f:\n",
    "            continue\n",
    "        \n",
    "        with open(f, 'r') as data_file:\n",
    "            normal_data.append(data_file.read().rstrip())\n",
    "\n",
    "# Load all the malicious system call traces (i.e., everything in Attack_Data_Master)\n",
    "\n",
    "# CODE HERE\n",
    "mal_data = []\n",
    "path = 'data/exercise3/Attack_Data_Master'\n",
    "dirs = [os.path.join(path, d) for d in os.listdir(path)]\n",
    "for d in dirs:\n",
    "    files = [os.path.join(d, f) for f in os.listdir(d)]\n",
    "    for f in files:\n",
    "        if '.txt' not in f:\n",
    "            continue\n",
    "\n",
    "        with open(f, 'r') as data_file:\n",
    "            mal_data.append(data_file.read().rstrip())\n",
    "\n",
    "# Hint: A useful way to load this is as one or two Python lists, where each entry in the list corresponds to the text string\n",
    "#       of system calls ids; feel free to use a single list for all the data, or separate lists for malicious versus normal\n",
    "#       data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "\n",
    "Tokenize and create a dataset where each datapoint corresponds to (normalized) counts of \n",
    "system call n-grams. Try various sizes of ngrams.\n",
    "\n",
    "Reminder: A sequence of system call IDs that looks like this:\n",
    "'6 6 63 6 42'\n",
    "\n",
    "contains the following 3-grams:\n",
    "'6 6 63'\n",
    "'6 63 6'\n",
    "'63 6 42'\n",
    "\n",
    "Note: There are a number of ways you could code this up, but if you loaded the data\n",
    "as lists of strings, you could consider using some of the feature extraction methods in \n",
    "sklearn.feature_extraction.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the classdemo notebook for an example of doing this\n",
    "# CODE HERE\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "count_vect = CountVectorizer(analyzer='word', ngram_range=(3,3))\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "\n",
    "raw_train_counts = count_vect.fit_transform(normal_data + mal_data)\n",
    "all_data = tf_transformer.fit_transform(raw_train_counts)\n",
    "\n",
    "all_labels = [0]*len(normal_data) + [1]*len(mal_data)\n",
    "all_labels = np.asarray(all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 50% of the data for the training set and the rest for the test set\n",
    "# CODE HERE\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(all_data, all_labels, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please use Logistic Regression for this exercise\n",
    "# Feel free to experiment with the various hyperparameters available to you in sklearn\n",
    "# CODE HERE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression().fit(x_train, y_train)\n",
    "\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# classifier = SGDClassifier(loss='log_loss', penalty='none', random_state=0).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96      2607\n",
      "           1       0.78      0.62      0.69       369\n",
      "\n",
      "    accuracy                           0.93      2976\n",
      "   macro avg       0.86      0.80      0.83      2976\n",
      "weighted avg       0.93      0.93      0.93      2976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run inference on the test data and predict labels for each data point in the test data\n",
    "# CODE HERE\n",
    "x_pred = classifier.predict(x_test)\n",
    "\n",
    "# Calculate and print the following metrics: precision, recall, f1-measure, and accuracy\n",
    "# CODE HERE\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, x_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Varying class priors\n",
    "\n",
    "Create several new test datasets where you have randomly subsampled the number of \n",
    "attack datapoints.\n",
    "\n",
    "In particular, create the following datasets:\n",
    "- 10 datasets where 25% of the attack datapoints are removed from the original test set\n",
    "- 10 datasets where 50% of the attack datapoints are removed from the original test set\n",
    "- 10 datasets where 75% of the attack datapoints are removed from the original test set\n",
    "- 10 datasets where 90% of the attack datapoints are removed from the original test set\n",
    "- 10 datasets where 95% of the attack datapoints are removed from the original test set\n",
    "\n",
    "Report five sets of precision, recall, f1-measure, and accuracy corresponding to the following:\n",
    "- Average precision, recall, f1-measure, accuracy for datasets where 25% of attack datapoints removed\n",
    "- Average precision, recall, f1-measure, accuracy for datasets where 50% of attack datapoints removed\n",
    "- Average precision, recall, f1-measure, accuracy for datasets where 75% of attack datapoints removed\n",
    "- Average precision, recall, f1-measure, accuracy for datasets where 90% of attack datapoints removed\n",
    "- Average precision, recall, f1-measure, accuracy for datasets where 95% of attack datapoints removed\n",
    "\n",
    "Note: You will use the same model trained in part 1 for all of these datasets.  \n",
    "All you are varying is the class priors during the inference stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with 0.25 percent of attackers removed\n",
      "   precision    recall        f1  accuracy\n",
      "0   0.960349  0.975451  0.967840  0.941381\n",
      "1   0.727613  0.619565  0.669228  0.941381\n",
      "\n",
      "Dataset with 0.5 percent of attackers removed\n",
      "   precision    recall        f1  accuracy\n",
      "0   0.973063  0.975451  0.974255  0.951845\n",
      "1   0.639545  0.617391  0.628232  0.951845\n",
      "\n",
      "Dataset with 0.75 percent of attackers removed\n",
      "   precision    recall        f1  accuracy\n",
      "0   0.986884  0.975451  0.981134  0.963764\n",
      "1   0.475909  0.632609  0.543093  0.963764\n",
      "\n",
      "Dataset with 0.9 percent of attackers removed\n",
      "   precision    recall        f1  accuracy\n",
      "0   0.994565  0.975451  0.984915  0.970526\n",
      "1   0.256111  0.613889  0.361376  0.970526\n",
      "\n",
      "Dataset with 0.95 percent of attackers removed\n",
      "   precision    recall        f1  accuracy\n",
      "0   0.997725  0.975451  0.986462   0.97341\n",
      "1   0.159621  0.677778  0.258366   0.97341\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create subsets of the test set by randomly discarding X% of points with label +1\n",
    "# CODE HERE\n",
    "from imblearn.datasets import make_imbalance\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "percents = [0.25, .5, .75, .9, .95]\n",
    "\n",
    "for p in percents:\n",
    "    class_rep = {'precision': 0, 'recall': 0, 'f1': 0, 'accuracy': 0}\n",
    "    for i in range(10):\n",
    "        sample_strat = {0: len(y_test) - sum(y_test), 1: int((1 - p)*sum(y_test))}\n",
    "        imbal_x, imbal_y = make_imbalance(x_test, y_test, sampling_strategy=sample_strat)\n",
    "\n",
    "        x_pred = classifier.predict(imbal_x)\n",
    "        # print(type(precision_score(imbal_y, x_pred)))\n",
    "        class_rep['precision'] += precision_score(imbal_y, x_pred, average=None)\n",
    "        class_rep['recall'] += recall_score(imbal_y, x_pred, average=None)\n",
    "        class_rep['f1'] += f1_score(imbal_y, x_pred, average=None)\n",
    "        class_rep['accuracy'] += accuracy_score(imbal_y, x_pred)\n",
    "\n",
    "    print(f'Dataset with {p} percent of attackers removed')\n",
    "    # pprint({k: class_rep[k] / 10 for k in class_rep.keys()})\n",
    "    results_df = pd.DataFrame({k: class_rep[k] / 10 for k in class_rep.keys()})\n",
    "    print(results_df)\n",
    "    print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "1) In Part 1, what size of ngrams gives the best performance? What are the tradeoffs as you change the size?\n",
    "\n",
    "The best size of ngrams is when n=3. Although the metrics for normal data does not change greatly depending on n with exceptions to precision and the f1 score increasing, all metrics for attack data increases from n = 1 to 3, then decreases afterwards. When n increases, the time it takes to generate the ngrams and train the model increases. \n",
    "\n",
    "2) In Part 1, how does performance change if we use simple counts as features (i.e., 1-grams) as opposed to counts of 2-grams? What does this tell you about the role of sequences in prediction for this dataset?\n",
    "\n",
    "Using 1-grams\n",
    "    precision    recall  f1-score   support\n",
    "\n",
    "0       0.90      0.98      0.94      2596\n",
    "1       0.68      0.25      0.37       380\n",
    "\n",
    "accuracy    0.89      2976\n",
    "\n",
    "Using 2-grams\n",
    "    precision    recall  f1-score   support\n",
    "\n",
    "0       0.94      0.98      0.96      2599\n",
    "1       0.80      0.56      0.66       377\n",
    "\n",
    "accuracy    0.93      2976\n",
    "\n",
    "From the abvoe results, nearly all metrics are improved from using 1-grams to using 2-grams. The metrics from normal data are largely unchanged, but training and testing with 2-grams helps the model improve its predictions for malicious data sequences.\n",
    "    \n",
    "The role of sequences are important for this dataset since if is difficult to tell from a single data point if it is normal or malicious. Using sequences of datapoints allows the model to see if a datapoint is an outlier compared to the rest of its sequence or if it is actually a malicious datapoint as it is grouped with multiple other malicious data points.\n",
    "\n",
    "3) How does performance change as a function of class prior in Part 2?\n",
    "\n",
    "For normal data, metrics remain mostly the same with slight increases in precision and f1 scores. This is to be expected since the model is less likely to predict false positives which affects precision and by extension, the f1 score. \n",
    "\n",
    "For malicious data, precision decreases since as the true positives are decreasing in each test dataset. Recall remains mostly unaffected with some variations between each test dataset. Overall, with a larger percentage of attacker datapoints removed from the test dataset, the model performs worse on the test dataset for the attacker class.\n",
    "\n",
    "Since the number of attacker datapoints are decreasing within the test set, we see improvements in accuracy even though the model performs worse for attacker data. This is due to the misclassifications being much smaller and decreasing compared to the normal predictions, that assumes more weight in the accuracy calcuation with each dataset.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "596935ea77931a3d3a0f7fec3d718aec427de1a662ceaadd9ccf6b25c30472da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
