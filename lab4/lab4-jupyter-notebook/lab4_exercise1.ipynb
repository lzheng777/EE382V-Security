{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4, Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data \n",
    "\n",
    "Here is an example of the first couple rows from the data:\n",
    "\n",
    "| id | dur       | proto | service | state | spkts | dpkts | sbytes | dbytes | rate        | sttl | dttl | sload     | dload | sloss | dloss | sinpkt | dinpkt | sjit | djit | swin | stcpb | dtcpb | dwin | tcprtt | synack | ackdat | smean | dmean | trans\\_depth | response\\_body\\_len | ct\\_srv\\_src | ct\\_state\\_ttl | ct\\_dst\\_ltm | ct\\_src\\_dport\\_ltm | ct\\_dst\\_sport\\_ltm | ct\\_dst\\_src\\_ltm | is\\_ftp\\_login | ct\\_ftp\\_cmd | ct\\_flw\\_http\\_mthd | ct\\_src\\_ltm | ct\\_srv\\_dst | is\\_sm\\_ips\\_ports | attack\\_cat | label |\n",
    "|----|-----------|-------|---------|-------|-------|-------|--------|--------|-------------|------|------|-----------|-------|-------|-------|--------|--------|------|------|------|-------|-------|------|--------|--------|--------|-------|-------|--------------|---------------------|--------------|----------------|--------------|---------------------|---------------------|-------------------|----------------|--------------|---------------------|--------------|--------------|--------------------|-------------|-------|\n",
    "| 1  | 0\\.000011 | udp   | \\-      | INT   | 2     | 0     | 496    | 0      | 90909\\.0902 | 254  | 0    | 180363632 | 0     | 0     | 0     | 0\\.011 | 0      | 0    | 0    | 0    | 0     | 0     | 0    | 0      | 0      | 0      | 248   | 0     | 0            | 0                   | 2            | 2              | 1            | 1                   | 1                   | 2                 | 0              | 0            | 0                   | 1            | 2            | 0                  | Normal      | 0     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and test data corresponding to exercise 1\n",
    "# Create two separate pandas dataframes for the training and test data\n",
    "# For each dataframe, import the following CSV data\n",
    "# training set: 'data/exercise1/UNSW_NB15_training-set.csv'\n",
    "# test set: 'data/exercise1/UNSW_NB15_testing-set.csv'\n",
    "\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 \n",
    "Keep the two dataframes separate and create train/test data and labels.  This will be used to experiment with the case where there are different types of activities in the training versus test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all the following operations in the cell on both the dataframes separately\n",
    "# 1) Keep only the datapoints where the 'attack_cat' column is equal to either 'Normal' or 'Fuzzers'\n",
    "# CODE HERE\n",
    "\n",
    "# 2) Get the labels from the dataframe (i.e., the values in the 'attack_cat' column)\n",
    "# CODE HERE\n",
    "\n",
    "# 3) Keep only the features we care about for this experiment.\n",
    "# We only care about the numerical features between column 'spkts' and 'is_sm_ips_ports' (inclusive)\n",
    "# CODE HERE\n",
    "\n",
    "# You should now have four inputs usable for scikit-learn:\n",
    "# training data\n",
    "# training labels\n",
    "# test data\n",
    "# test labels\n",
    "# Hint: You may have to add some minor code in the above to get the data ready for scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 \n",
    "Create a new training/test split by combining the dataframes into one.  Then split the dataframe randomly into train/test data and labels.  This will be used to experiment with the case where there are largely the same types of activities in the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the dataframes into a single dataframe, then do the following\n",
    "# CODE HERE\n",
    "\n",
    "# 1) Keep only the datapoints where the 'attack_cat' column is equal to either 'Normal' or 'Fuzzers'\n",
    "# CODE HERE\n",
    "\n",
    "# 2) Get the labels from the dataframe (i.e., the values in the 'attack_cat' column)\n",
    "# CODE HERE\n",
    "\n",
    "# 3) Keep only features we care about for this experiment.\n",
    "# We only care about the numerical features between column 'spkts' and 'is_sm_ips_ports' (inclusive)\n",
    "# CODE HERE\n",
    "\n",
    "# 4) Create a random split; put 50% of the data into the training set and the other 50% into the test set\n",
    "# Use scikit-learn's 'train_test_split'\n",
    "# Hint: You may have to add some minor code in the above to get the data ready for scikit-learn's 'train_test_split'\n",
    "# CODE HERE\n",
    "\n",
    "# You should now have four inputs usable for scikit-learn that are distinct from the inputs you created in Part 1.\n",
    "# The inputs should correspond to:\n",
    "# training data\n",
    "# training labels\n",
    "# test data\n",
    "# test labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of the train/test splits, create a separate random forest with default sklearn parameters\n",
    "# Hint: Ignoring import statements, each random forest can be created in a single line of code\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of the train/test splits and associated random forest, do the following:\n",
    "\n",
    "# 1) Predict labels on the training data\n",
    "# CODE HERE\n",
    "\n",
    "# 2) Print metrics on the training data; use sklearn's implementation of precision, recall, f1, and accuracy\n",
    "# CODE HERE\n",
    "\n",
    "# 3) Predict labels on the test data\n",
    "# CODE HERE\n",
    "\n",
    "# 4) Print metrics on the test data; again, use precision, recall, f1, and accuracy\n",
    "# CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "\n",
    "1) For results using Part 1 data, what is the precision and recall?\n",
    "\n",
    "2) For results using Part 1 data, describe the difference in the results on the training and test data. What does this signify? \n",
    "\n",
    "3) What changes in the results on the test data once you combine the data for Part 2? Does this produce a better classifier? Why or why not?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
