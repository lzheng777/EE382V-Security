{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4, Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data \n",
    "\n",
    "Here is an example of the first couple rows from the data:\n",
    "\n",
    "| id | dur       | proto | service | state | spkts | dpkts | sbytes | dbytes | rate        | sttl | dttl | sload     | dload | sloss | dloss | sinpkt | dinpkt | sjit | djit | swin | stcpb | dtcpb | dwin | tcprtt | synack | ackdat | smean | dmean | trans\\_depth | response\\_body\\_len | ct\\_srv\\_src | ct\\_state\\_ttl | ct\\_dst\\_ltm | ct\\_src\\_dport\\_ltm | ct\\_dst\\_sport\\_ltm | ct\\_dst\\_src\\_ltm | is\\_ftp\\_login | ct\\_ftp\\_cmd | ct\\_flw\\_http\\_mthd | ct\\_src\\_ltm | ct\\_srv\\_dst | is\\_sm\\_ips\\_ports | attack\\_cat | label |\n",
    "|----|-----------|-------|---------|-------|-------|-------|--------|--------|-------------|------|------|-----------|-------|-------|-------|--------|--------|------|------|------|-------|-------|------|--------|--------|--------|-------|-------|--------------|---------------------|--------------|----------------|--------------|---------------------|---------------------|-------------------|----------------|--------------|---------------------|--------------|--------------|--------------------|-------------|-------|\n",
    "| 1  | 0\\.000011 | udp   | \\-      | INT   | 2     | 0     | 496    | 0      | 90909\\.0902 | 254  | 0    | 180363632 | 0     | 0     | 0     | 0\\.011 | 0      | 0    | 0    | 0    | 0     | 0     | 0    | 0      | 0      | 0      | 248   | 0     | 0            | 0                   | 2            | 2              | 1            | 1                   | 1                   | 2                 | 0              | 0            | 0                   | 1            | 2            | 0                  | Normal      | 0     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and test data corresponding to exercise 1\n",
    "# Create two separate pandas dataframes for the training and test data\n",
    "# For each dataframe, import the following CSV data\n",
    "# training set: 'data/exercise1/UNSW_NB15_training-set.csv'\n",
    "# test set: 'data/exercise1/UNSW_NB15_testing-set.csv'\n",
    "\n",
    "# CODE HERE\n",
    "train_df = pd.read_csv('data/exercise1/UNSW_NB15_training-set.csv')\n",
    "test_df = pd.read_csv('data/exercise1/UNSW_NB15_testing-set.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 \n",
    "Keep the two dataframes separate and create train/test data and labels.  This will be used to experiment with the case where there are different types of activities in the training versus test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all the following operations in the cell on both the dataframes separately\n",
    "# 1) Keep only the datapoints where the 'attack_cat' column is equal to either 'Normal' or 'Fuzzers'\n",
    "# CODE HERE\n",
    "train_set = train_df.loc[train_df['attack_cat'].isin(['Normal', 'Fuzzers'])]\n",
    "test_set = test_df.loc[test_df['attack_cat'].isin(['Normal', 'Fuzzers'])]\n",
    "\n",
    "# 2) Get the labels from the dataframe (i.e., the values in the 'attack_cat' column)\n",
    "# CODE HERE\n",
    "train_label = train_set['attack_cat'].tolist()\n",
    "test_label = test_set['attack_cat'].tolist()\n",
    "\n",
    "# 3) Keep only the features we care about for this experiment.\n",
    "# We only care about the numerical features between column 'spkts' and 'is_sm_ips_ports' (inclusive)\n",
    "# CODE HERE\n",
    "col_names = list(train_set.columns)\n",
    "col_headers = col_names[col_names.index('spkts'):col_names.index('is_sm_ips_ports') + 1]\n",
    "train_set = train_set.filter(items=col_headers)\n",
    "test_set = test_set.filter(items=col_headers)\n",
    "\n",
    "# You should now have four inputs usable for scikit-learn:\n",
    "# training data\n",
    "# training labels\n",
    "# test data\n",
    "# test labels\n",
    "# Hint: You may have to add some minor code in the above to get the data ready for scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 \n",
    "Create a new training/test split by combining the dataframes into one.  Then split the dataframe randomly into train/test data and labels.  This will be used to experiment with the case where there are largely the same types of activities in the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the dataframes into a single dataframe, then do the following\n",
    "# CODE HERE\n",
    "combine_df = pd.concat([train_df, test_df])\n",
    "\n",
    "# 1) Keep only the datapoints where the 'attack_cat' column is equal to either 'Normal' or 'Fuzzers'\n",
    "# CODE HERE\n",
    "combine_set = combine_df.loc[combine_df['attack_cat'].isin(['Normal', 'Fuzzers'])]\n",
    "\n",
    "# 2) Get the labels from the dataframe (i.e., the values in the 'attack_cat' column)\n",
    "# CODE HERE\n",
    "combine_label = combine_set['attack_cat'].tolist()\n",
    "\n",
    "# 3) Keep only features we care about for this experiment.\n",
    "# We only care about the numerical features between column 'spkts' and 'is_sm_ips_ports' (inclusive)\n",
    "# CODE HERE\n",
    "col_names = list(combine_set.columns)\n",
    "col_headers = col_names[col_names.index('spkts'):col_names.index('is_sm_ips_ports') + 1]\n",
    "combine_set = combine_set.filter(items=col_headers)\n",
    "\n",
    "# 4) Create a random split; put 50% of the data into the training set and the other 50% into the test set\n",
    "# Use scikit-learn's 'train_test_split'\n",
    "# Hint: You may have to add some minor code in the above to get the data ready for scikit-learn's 'train_test_split'\n",
    "# CODE HERE\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(combine_set, combine_label, test_size=0.5)\n",
    "\n",
    "# You should now have four inputs usable for scikit-learn that are distinct from the inputs you created in Part 1.\n",
    "# The inputs should correspond to:\n",
    "# training data\n",
    "# training labels\n",
    "# test data\n",
    "# test labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each of the train/test splits, create a separate random forest with default sklearn parameters\n",
    "# Hint: Ignoring import statements, each random forest can be created in a single line of code\n",
    "# CODE HERE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnd_forest = RandomForestClassifier().fit(train_set, train_label)\n",
    "rnd_forest2 = RandomForestClassifier().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Fuzzers       1.00      1.00      1.00      6062\n",
      "      Normal       1.00      1.00      1.00     37000\n",
      "\n",
      "    accuracy                           1.00     43062\n",
      "   macro avg       1.00      1.00      1.00     43062\n",
      "weighted avg       1.00      1.00      1.00     43062\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Fuzzers       0.99      0.99      0.99     12169\n",
      "      Normal       1.00      1.00      1.00     46454\n",
      "\n",
      "    accuracy                           1.00     58623\n",
      "   macro avg       0.99      0.99      0.99     58623\n",
      "weighted avg       1.00      1.00      1.00     58623\n",
      "\n",
      "Test data results\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Fuzzers       0.88      0.20      0.33     18184\n",
      "      Normal       0.79      0.99      0.88     56000\n",
      "\n",
      "    accuracy                           0.80     74184\n",
      "   macro avg       0.84      0.60      0.61     74184\n",
      "weighted avg       0.81      0.80      0.75     74184\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Fuzzers       0.78      0.72      0.75     12077\n",
      "      Normal       0.93      0.95      0.94     46546\n",
      "\n",
      "    accuracy                           0.90     58623\n",
      "   macro avg       0.85      0.83      0.84     58623\n",
      "weighted avg       0.90      0.90      0.90     58623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each of the train/test splits and associated random forest, do the following:\n",
    "from sklearn.metrics import classification_report\n",
    "# 1) Predict labels on the training data\n",
    "# CODE HERE\n",
    "pred_label = rnd_forest.predict(train_set)\n",
    "pred_label2 = rnd_forest2.predict(x_train)\n",
    "\n",
    "# 2) Print metrics on the training data; use sklearn's implementation of precision, recall, f1, and accuracy\n",
    "# CODE HERE\n",
    "print('Training data results')\n",
    "print(classification_report(train_label, pred_label))\n",
    "print(classification_report(y_train, pred_label2))\n",
    "\n",
    "# 3) Predict labels on the test data\n",
    "# CODE HERE\n",
    "pred_label = rnd_forest.predict(test_set)\n",
    "pred_label2 = rnd_forest2.predict(x_test)\n",
    "\n",
    "# 4) Print metrics on the test data; again, use precision, recall, f1, and accuracy\n",
    "# CODE HERE\n",
    "print('Test data results')\n",
    "print(classification_report(test_label, pred_label))\n",
    "print(classification_report(y_test, pred_label2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "\n",
    "1) For results using Part 1 data, what is the precision and recall?\n",
    "\n",
    "For the Part 1 data, the precision on the test dataset is 0.88 for fuzzers and 0.79 for normal and recall on the test dataset is 0.20 for fuzzers and 0.99 for normal. This means that both normal and fuzzer traffic has approximately the same precision and are more likely to have fewer false positives compared to true positives. The recall values means that normal traffic is predicted correctly most of the time, but there are many false negatives for fuzzer datapoints that are classified as normal.\n",
    "\n",
    "2) For results using Part 1 data, describe the difference in the results on the training and test data. What does this signify? \n",
    "\n",
    "The results of the training and test datasets for the first random forest classifier show that the classifier can accurately and precisely classify the training data, as the values are 1. Compared to the test data, all metrics are smaller than the training metrics to show that the classifier can incorrectly classify the data in the test dataset. This shows that the random forest was correctly trained on the training dataset and has not seen portions of the test dataset.\n",
    "\n",
    "3) What changes in the results on the test data once you combine the data for Part 2? Does this produce a better classifier? Why or why not?\n",
    "\n",
    "Yes. Accuracy for the second random forest is higher than the first random forest (0.9 vs 0.8 respectively). The F1 scores for the second random forest is also higher than the first random forest to indicate that the average precision and recall for normal and fuzzers are improved with the second dataset. This means that the test data for the first classifier varies quite a bit compared to the training dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "596935ea77931a3d3a0f7fec3d718aec427de1a662ceaadd9ccf6b25c30472da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
