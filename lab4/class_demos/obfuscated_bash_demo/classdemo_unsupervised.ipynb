{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sKqrJMOKffAw"
   },
   "source": [
    "# Unsupervised learning for detecting obfuscated bash commands\n",
    "\n",
    "In this Jupyter notebook, we will study a dataset comprised of bash commands and obfuscated versions of them, using unsupervised learning approaches such as clustering and anomaly detection to try to detect these obfuscated (and therefore likely malicious) commands. The purpose of this exercise is to demonstrate some unsupervised learning pipelines, consisting of feature extraction, learning and qualitatively exploring the results of an unsupervised model, and quantitatively evaluating it in the rare instance that we have labels.\n",
    "\n",
    "In order to circumvent simple, signature-based detectors for suspicious commands executed in the shell, attackers may choose to obfuscate their commands using automated methods. Such tools take a normal command as input and generate a version that is functionally the same but looks significantly different, and would therefore escape detection by a signature-based detector. The obfuscation tool we will be using to generate our example dataset is Bashfuscator [1], which works with bash commands.\n",
    "\n",
    "To generate our example dataset, we downloaded a set of normal (i.e., unobfuscated) bash commands from a project called NL2Bash [2]. This data consists of a set of ~12K bash one-liners [3] collected from websites such as StackOverflow. Using Bashfuscator and a subset of these commands, we generated ~1200 obfuscated bash commands.\n",
    "\n",
    "### References\n",
    "[1] https://github.com/Bashfuscator/Bashfuscator\n",
    "\n",
    "[2] https://github.com/TellinaTool/nl2bash\n",
    "\n",
    "[3] https://github.com/TellinaTool/nl2bash/blob/master/data/bash/all.cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TFQANgUyU8RS"
   },
   "source": [
    "## Load data\n",
    "For this exercise, the data collection and pre-processing steps have already been completed as described earlier, and that we only need to load this dataset in order to start using it.\n",
    "\n",
    "Note that for an unsupervised learning pipeline, we typically don't have labels for the data--if we did, we would have used a supervised approach! However, for the purpose of quantatively evaluating performance of our unsupervised methods later on, when we load the dataset we will retain labels (+1 for obfuscated commands and -1 for unobfuscated commands) so that we can compare the performance of our unsupervised methods to earlier supervised approaches. **We do not require or use these labels when training our unsupervised methods.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JmB2lg-v0Kxg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "# Load raw text\n",
    "nor_text = list()\n",
    "mal_text = list()\n",
    "\n",
    "# Load unobfuscated commands\n",
    "sample_proportion_nor = 1  # lower to decrease class imbalance\n",
    "my_file = 'data/bash_commands'\n",
    "with open(my_file) as f:\n",
    "    for i,line in enumerate(f):\n",
    "        if random.random() < sample_proportion_nor:\n",
    "            cmd = line.rstrip()\n",
    "            nor_text.append(cmd)\n",
    "\n",
    "# Load obfuscated commands\n",
    "sample_proportion_mal = 0.1  # lower to increase class imbalance\n",
    "my_file = 'data/obs_bash_commands'\n",
    "with open(my_file) as f:\n",
    "    for i,line in enumerate(f):\n",
    "        if random.random() < sample_proportion_mal:\n",
    "            cmd = line.rstrip()\n",
    "            mal_text.append(cmd)\n",
    "\n",
    "# Count number of normal and malicious commands\n",
    "num_nor = len(nor_text)\n",
    "num_mal = len(mal_text)\n",
    "print('\\nLoaded %s normal commands and %s obfuscated commmands.' % (num_nor, num_mal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rlk8Fh3I4r-L"
   },
   "source": [
    "### Examples from dataset\n",
    "Let's first look at some examples of normal and obfuscated bash commands to better understand the task at hand. This step of manually inspecting the data and trying to understand its features and peculiarities is an important and necessary one, as it informs us on the type of model we may want to use to best solve our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U8Iao9y6hx8t"
   },
   "outputs": [],
   "source": [
    "# Examples of normal bash commands\n",
    "print('Normal bash examples:')\n",
    "for elem in nor_text[0:10]: print('(len: ' + str(len(elem)) + ') ' + elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IpcXVVkjkS9m"
   },
   "outputs": [],
   "source": [
    "# Examples of obfuscated bash commands\n",
    "print('Obfuscated bash examples:')\n",
    "for elem in mal_text[0:10]: print('(len: ' + str(len(elem)) + ') ' + elem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I864Nr5e-cs0"
   },
   "source": [
    "### Length of commands\n",
    "We inspect the distribution of lengths of normal and obfuscated commands to determine whether there are any patterns that can be used to discriminate between the two classes.\n",
    "\n",
    "*Bonus: Can you prescribe a hand-coded set of rules (based on command length) that does well at discriminating between normal and obfuscated commands?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qjt0JWyfzPqd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute log (base 10) lengths of normal and obfuscated commands\n",
    "len_nor = [len(elem) for elem in nor_text]\n",
    "loglen_nor = np.log10(len_nor)\n",
    "\n",
    "len_mal = [len(elem) for elem in mal_text]\n",
    "loglen_mal = np.log10(len_mal)\n",
    "\n",
    "# Evalute max of log lengths\n",
    "print('Max. log length for normal commands: ' + str(np.max(loglen_nor)))\n",
    "print('Max. log length for obfuscated commands: ' + str(np.max(loglen_mal)))\n",
    "\n",
    "# Plot density\n",
    "bins = np.linspace(0, 8, 160)\n",
    "plt.hist(loglen_nor, bins, density=True, alpha=0.5, label='normal')\n",
    "plt.hist(loglen_mal, bins, density=True, alpha=0.5, label='obfuscated')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Density plot of log (base 10) command lengths')\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = [8,6]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ntO9FPDV3zhJ"
   },
   "outputs": [],
   "source": [
    "# Truncate obfuscated commands\n",
    "truncate = True\n",
    "hard_truncate = False\n",
    "max_length = 100\n",
    "\n",
    "if truncate:\n",
    "    if hard_truncate:\n",
    "        # Truncate all obfuscated commands at specified max length\n",
    "        mal_text = [elem[:max_length] for elem in mal_text]\n",
    "    else:\n",
    "        # Truncate obfuscated commands according to normal command length distribution\n",
    "        mal_text = [elem[:random.choice(len_nor)] for elem in mal_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DWZuvfKIVFJM"
   },
   "source": [
    "## Feature extraction\n",
    "We now perform feature extraction on a labeled dataset comprised of both normal and obfuscated commands. To do this, we will use the `CountVectorizer` function in scikit-learn to generate a set of features based on $n$-grams of words or characters (or some other user-specified criterion), then compute the number of occurrences of every feature within each command. Each such count vector can be thought of a vector representation (e.g., an embedding) of the command from which it was generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HDEl678t_9M7"
   },
   "outputs": [],
   "source": [
    "# Merge normal/obfuscated commands into one labeled dataset\n",
    "raw_text = nor_text + mal_text\n",
    "raw_labels = [-1]*num_nor + [1]*num_mal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BlJXAcZE0P0d"
   },
   "outputs": [],
   "source": [
    "# Build feature extractor\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#count_vect = CountVectorizer()\n",
    "count_vect = CountVectorizer(analyzer='char', ngram_range=(1,1))  # character n-gram feature extraction\n",
    "\n",
    "# Extract feature counts\n",
    "raw_counts = count_vect.fit_transform(raw_text)\n",
    "\n",
    "# Display features\n",
    "features = count_vect.get_feature_names()\n",
    "print('Feature set: ' + str(features))\n",
    "print('Number of features: ' + str(len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BcgqjOtGBi7n"
   },
   "outputs": [],
   "source": [
    "# Normalize counts\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tf_transformer = TfidfTransformer(use_idf=False)\n",
    "all_data = tf_transformer.fit_transform(raw_counts)\n",
    "\n",
    "# Convert labels to numpy array\n",
    "import numpy as np\n",
    "all_labels = np.asarray(raw_labels)\n",
    "\n",
    "# Create set of indices\n",
    "indices = np.arange(len(all_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ItVaVhl8U2PD"
   },
   "source": [
    "## Unsupervised learning\n",
    "Next, we can learn an unsupervised model that tries to distinguish parts of the feature space that correspond to each of the two classes: normal vs. obfuscated (anomalous). We will focus on k-means clustering (a clustering method) and isolation forests (a tree-based approach for anomaly detection) in order to illustrate how these models can be utilized, and will later show how their results can be analyzed and interpreted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RQAuX8igWOx9"
   },
   "source": [
    "### K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NBcyXeRnWNBM"
   },
   "outputs": [],
   "source": [
    "# Cluster test data using k-means\n",
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters=2, random_state=0).fit(all_data)\n",
    "model_type = 'clustering'\n",
    "\n",
    "# Print resulting cluster labels\n",
    "print('Cluster labels: ' + str(model.labels_))\n",
    "#print('Cluster centers: ' + str(model.cluster_centers_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kjaLWldTOhig"
   },
   "outputs": [],
   "source": [
    "# Compute silhouette score (measure of cluster consistency, ranging from -1 (poor consistency) to +1 (good consistency))\n",
    "from sklearn.metrics import silhouette_score\n",
    "print('Silhouette score: ' + str(silhouette_score(all_data, model.labels_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8oweP4eKOdsc"
   },
   "source": [
    "### Isolation forest (anomaly detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mBPkDDViOdCL"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "model = IsolationForest(max_samples=100, random_state=0, behaviour='new', contamination='auto').fit(all_data)\n",
    "model_type = 'anomaly detection'\n",
    "\n",
    "# Compute anomaly scores and labels (label 1 if anomaly score is negative)\n",
    "anomaly_scores = model.decision_function(all_data)\n",
    "model.labels_ = (anomaly_scores < 0).astype(int)\n",
    "print('Anomaly scores: ' + str(anomaly_scores))\n",
    "print('Anomaly labels: ' + str(model.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u1ZKhTrzQsQU"
   },
   "outputs": [],
   "source": [
    "# Evalute max/min of anomaly scores\n",
    "print('Max. anomaly score: ' + str(np.max(anomaly_scores)))\n",
    "print('Min. anomaly score: ' + str(np.min(anomaly_scores)))\n",
    "\n",
    "# Plot density\n",
    "bins = np.linspace(np.min(anomaly_scores), np.max(anomaly_scores), 160)\n",
    "plt.hist(anomaly_scores, bins, density=True, alpha=0.5, label='anomaly scores')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Density plot of anomaly scores from isolation forest')\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = [8,6]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ybq_PjbkKrow"
   },
   "source": [
    "## Qualitative results (i.e., intrinsic evaluation)\n",
    "\n",
    "Since we do not have labels when performing unsupervised learning, we can only perform an evaluation of the model results using intrinsic measures of “goodness” (e.g., consistency of clusters for k-means or distribution of anomaly scores from isolation forest).\n",
    "\n",
    "We can also try to visualize the results of these methods, which requires us to project our high-dimensional feature vectors to two- or three-dimensional plots. There are many methods for doing so, and their performance largely depends on the characteristics of the dataset being visualized. Besides linear projection methods like principal component analysis (PCA), one can also use nonlinear methods like manifold learning to try to discern lower-dimensional structure in the dataset under consideration.\n",
    "\n",
    "One such nonlinear method is t-distributed stochastic neighbor embedding (t-SNE), which tries to capture local structure in the data manifold. Note that t-SNE (like all manifold learning methods) can produce visualizations that are quite deceptive, implying structures and clusters that may not actually exist in the dataset. For further discussion and an interactive ilustration of the capabilities and potential pitfalls of t-SNE, we refer to [4] and [5].\n",
    "\n",
    "### References\n",
    "\n",
    "[4] https://mlexplained.com/2018/09/14/paper-dissected-visualizing-data-using-t-sne-explained/\n",
    "\n",
    "[5] https://distill.pub/2016/misread-tsne/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pdBB8OdXlFwi"
   },
   "source": [
    "#### t-SNE plot of feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dkt543FSUEcm"
   },
   "outputs": [],
   "source": [
    "# Compute 2-d TSNE projection\n",
    "from sklearn.manifold import TSNE\n",
    "num_points = 1000\n",
    "sample_indices = random.sample(list(indices), num_points)\n",
    "tsne = TSNE(n_components=2, init='random', random_state=0)\n",
    "tsne_proj = tsne.fit_transform(all_data[sample_indices].todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YRMI7bDLiSGj"
   },
   "outputs": [],
   "source": [
    "# Create TSNE plot (colored by cluster/anomaly labels)\n",
    "import matplotlib.pyplot as plt \n",
    "colors = 'c', 'g'\n",
    "for i, c in zip([0,1], colors):\n",
    "    plt.scatter(tsne_proj[model.labels_[sample_indices] == i, 0], tsne_proj[model.labels_[sample_indices] == i, 1], c=c)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3r8DwE7QPuUI"
   },
   "source": [
    "What if we had ground truth lables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-QbgBo4PPs8M"
   },
   "outputs": [],
   "source": [
    "# Create TSNE plot (colored by ground truth labels)\n",
    "import matplotlib.pyplot as plt\n",
    "colors = 'b', 'r'\n",
    "for i, c in zip([-1,1], colors):\n",
    "    plt.scatter(tsne_proj[all_labels[sample_indices] == i, 0], tsne_proj[all_labels[sample_indices] == i, 1], c=c)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HAfVCiNqZ32u"
   },
   "source": [
    "## Quantitative evaluation given labels (extrinsic evaluation)\n",
    "While we typically do not have a labelled dataset when using an unsupervised ML pipeline, if we do have access to the labels we can perform a more comprehensive evaluation of the method being used. In this section, we build the unsupervised model on a training set (without labels) and fit it to a test set to study its performance as a classifier by using ground truth labels and the same metrics introduced in the supervised ML pipeline. We can also take a closer look at those examples that were misclassified and try to discern the reasons why prediction may have failed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k0DjVKblaGVh"
   },
   "source": [
    "### Train/test split\n",
    "In order to not overfit the model and miscalculate its true performance, we must first split the dataset into a training set and a test set. In the following sections, we will train a model using feature vectors and corresponding labels from the training set (see **Model training**), and evaluate its performance by predicting labels using only feature vectors from the test set (see **Inference**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Eq9eeBhQaJva"
   },
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Include indices for tracking of individual data points after splitting\n",
    "train_data, test_data, train_labels, test_labels, train_indices, test_indices = train_test_split(all_data, all_labels, indices, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OZrb3sFtGw-d"
   },
   "source": [
    "### Model training and prediction\n",
    "Next, we can train a classifier that tries to learn which parts of the feature space correspond to each of the two classes: normal vs. obfuscated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gSifPlDuGw-e"
   },
   "source": [
    "#### K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BT4DopMLGw-f"
   },
   "outputs": [],
   "source": [
    "# Cluster test data using k-means\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Train model assuming only two clusters in data\n",
    "classifier = KMeans(n_clusters=2, random_state=2).fit(train_data)\n",
    "classifier_type = 'clustering'\n",
    "\n",
    "# Predict labels for test data, with clusters 0 and 1 mapped to negative and positive class, respectively (arbitary choice)\n",
    "predicted_labels = classifier.predict(test_data)\n",
    "predicted_labels = np.where(predicted_labels==0, -1, predicted_labels)\n",
    "\n",
    "# Assign classifier classes\n",
    "classifier.classes_ = [-1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z8kPnWD7UPXK"
   },
   "source": [
    "#### Isolation forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mcWq9G644GsN"
   },
   "outputs": [],
   "source": [
    "# Perform anomaly detection on test data\n",
    "from sklearn.ensemble import IsolationForest\n",
    "classifier = IsolationForest(max_samples=100, random_state=0, behaviour='new', contamination='auto').fit(train_data)\n",
    "classifier_type = 'anomaly detection'\n",
    "\n",
    "# Predict labels for test data, with negative anomaly scores (most anomalous) labeled as obfuscated\n",
    "anomaly_scores = classifier.decision_function(test_data)\n",
    "predicted_labels = (anomaly_scores < 0).astype(int)\n",
    "predicted_labels = np.where(predicted_labels==0, -1, predicted_labels)\n",
    "\n",
    "# Assign classifier classes\n",
    "classifier.classes_ = [-1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g_1kOICNo3bs"
   },
   "source": [
    "### Analyze performance\n",
    "We consider the performance of our classifier by looking at metrics such as precision, recall, F1-measure, and accuracy. These can also be built using the confusion matrix, which is essentially a histogram of the predicted labels and true lables of examples in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gujD1MssveIQ"
   },
   "outputs": [],
   "source": [
    "# Analyze performance\n",
    "from sklearn import metrics\n",
    "\n",
    "if classifier_type == 'clustering':\n",
    "    nmi_score = sklearn.metrics.normalized_mutual_info_score(test_labels, predicted_labels, average_method='arithmetic')\n",
    "    print('NMI between cluster labels and class labels: \\n' + str(nmi_score))\n",
    "    print('\\n')\n",
    "\n",
    "# Classification report\n",
    "#print(metrics.classification_report(test_labels, predicted_labels))\n",
    "\n",
    "# Standard metrics\n",
    "precision = metrics.precision_score(test_labels, predicted_labels)\n",
    "recall = metrics.recall_score(test_labels, predicted_labels)\n",
    "f1measure = metrics.f1_score(test_labels, predicted_labels)\n",
    "accuracy = metrics.accuracy_score(test_labels, predicted_labels)\n",
    "\n",
    "print(' precision = ' + str(precision))\n",
    "print('    recall = ' + str(recall))\n",
    "print('F1-measure = ' + str(f1measure))\n",
    "print('  accuracy = ' + str(accuracy))\n",
    "print('\\n')\n",
    "\n",
    "# Confusion matrix\n",
    "print('Confusion matrix (text-only):')\n",
    "cm = metrics.confusion_matrix(test_labels, predicted_labels, classifier.classes_)\n",
    "print(classifier.classes_)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "SHbJqFL-l1Bn"
   },
   "outputs": [],
   "source": [
    "# Plot fancy confusion matrix\n",
    "# Reference: https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    #    print(\"Normalized confusion matrix\")\n",
    "    #else:\n",
    "    #    print('Confusion matrix, without normalization')\n",
    "        \n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.4f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "\n",
    "# Pretty plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(test_labels, predicted_labels, classes=['normal','obfuscated'],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Pretty plot normalized confusion matrix\n",
    "plot_confusion_matrix(test_labels, predicted_labels, classes=['normal','obfuscated'], normalize=True,\n",
    "                      title='Normalized confusion matrix, by true label')\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = [6,6]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eWxUv9Y2oycX"
   },
   "source": [
    "### Inspect misclassified examples\n",
    "By looking at those examples that were misclassified, we can better understand what the classifier has learned and how it could potentially be improved. In our case, each misclassified example is either (i) a command marked as obfuscated although it was actually normal (i.e., a false positive) or (ii) a command marked as normal although it was actually obfuscated (i.e., a false negative). It is largely domain-dependent to determine how to balance the cost of a false negative versus a false positive, and which we'd prefer our model to try to avoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F3rhieJyW9hL"
   },
   "outputs": [],
   "source": [
    "# Show misclassified examples\n",
    "misclassified_fp = np.where((test_labels != predicted_labels) & (predicted_labels == np.ones(len(predicted_labels))))\n",
    "misclassified_fn = np.where((test_labels != predicted_labels) & (predicted_labels != np.ones(len(predicted_labels))))\n",
    "\n",
    "false_positives = [raw_text[index] for index in test_indices[misclassified_fp]]\n",
    "print('False positives (marked as obfuscated, but actually normal):')\n",
    "for elem in false_positives:\n",
    "    print(elem)\n",
    "print('\\n')\n",
    "\n",
    "false_negatives = [raw_text[index] for index in test_indices[misclassified_fn]]\n",
    "print('False negatives (marked as normal, but actually obfuscated):')\n",
    "for elem in false_negatives:\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "I864Nr5e-cs0"
   ],
   "name": "classdemo_unsupervised.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "596935ea77931a3d3a0f7fec3d718aec427de1a662ceaadd9ccf6b25c30472da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
